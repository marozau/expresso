stream.kafka {

  producer {

    pool.size = 1

    schema.registry.url = "http://localhost:8081"

    bootstrap.servers = "localhost:9092"

    acks = all

    client.id = "1" //need to be incremental for each instance of the server
    transactional.id = "1" //need to be incremental for each instance of the server

    enable.idempotence = true
    max.in.flight.requests.per.connection = 1

    blocking-dispatcher {
      executor = "thread-pool-executor"
      throughput = 1
      thread-pool-executor {
        fixed-pool-size = 1
      }
    }
  }

  streams {

    application.id = "streams"

    schema.registry.url = "http://localhost:8081"
    bootstrap.servers = "localhost:9092"

    processing.guarantee = "exactly_once"

    default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndContinueExceptionHandler
    default.production.exception.handler =  today.expresso.stream.errors.LogAndContinueExceptionHandler
    default.timestamp.extractor = class org.apache.kafka.streams.processor.LogAndSkipOnInvalidTimestamp
  }
}